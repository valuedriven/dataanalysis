# Questões diversas

Tunning de hyperparameters

Métricas:
f1: 2 * (precision * recall) / (precision + recall)

precision: tp / (tp + fp)

recall: tp / (tp + fn)

https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics
https://scikit-learn.org/stable/modules/model_evaluation.html
https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html
https://github.com/chongjason914/scikit-learn-tutorial/blob/main/feature-encoding.ipynb
https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html
https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234
https://neptune.ai/blog/performance-metrics-in-machine-learning-complete-guide
https://www.kdnuggets.com/2019/10/5-classification-evaluation-metrics-every-data-scientist-must-know.html
https://www.altexsoft.com/blog/machine-learning-metrics/
https://medium.com/analytics-vidhya/model-evaluation-metrics-in-machine-learning-928999fb79b2

Referência sobre melhores indicações de cada método

Referências para escolher hyperparâmetros mais significativos que podem ser exercitados
 
Referências sobre métricas e, principalmente, se os valores estão aceitáveis



